{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f63cad0-3c0d-44aa-9556-5502c49e91b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6acbd3-6a12-4c08-8835-684edc04e4e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daba226c-cf42-4daa-a7d2-ea04ea443b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('/home/ubuntu/MovieLens/ratings.dat', sep='::', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')\n",
    "movies_df = pd.read_csv('/home/ubuntu/MovieLens/movies.dat', sep='::', header=None, names=['movie_id', 'title', 'genres'], engine='python', encoding='latin1')\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec488e6-dac0-41fa-a654-5da2385a589d",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be56ecc-7d51-45bd-adb5-6bcf5530f6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_genres = set() # 映画ジャンルの集合（重複なし）\n",
    "for genres in movies_df['genres']:\n",
    "    unique_genres.update(genres)\n",
    "\n",
    "genre2id = {genre: idx for idx, genre in enumerate(unique_genres)} # ジャンルがキー，対応するIDが値\n",
    "\n",
    "adj_list = defaultdict(set) # 映画とそのジャンルの隣接リスト（辞書），キーが存在しないときは空集合を返す\n",
    "for _, row in movies_df.iterrows(): \n",
    "    movie_id = row['movie_id']\n",
    "    for genre in row['genres']: # 各映画のジャンルリスト\n",
    "        genre_id = genre2id[genre] # 各ジャンルに対応するIDを取得\n",
    "        adj_list[movie_id].add(len(movies_df) + genre_id)\n",
    "        adj_list[len(movies_df) + genre_id].add(movie_id) # 映画とジャンル間のリンクを隣接リストに追加\n",
    "\n",
    "for key in adj_list: \n",
    "    adj_list[key] = list(map(int, adj_list[key])) # 映画と関連するジャンルのリスト．mapで各要素を整数に"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd55e27-70cf-43d8-9b59-bd2e293e8a27",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd04ab43-20cd-4ea2-9ccf-5999edaedc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KGAT(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_genres, embedding_dim): #初期化関数：ユーザー数，アイテム（映画+ジャンル）数，ジャンル数，埋め込みの次元数\n",
    "        super(KGAT, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim) # ユーザーの埋め込みベクトル\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim) # アイテムの埋め込みベクトル\n",
    "        \n",
    "        self.user_attention = nn.Linear(embedding_dim, 1) # ユーザーのAttentionを計算する線形層\n",
    "        self.item_attention = nn.Linear(embedding_dim, 1) # アイテムのAttentionを計算する線形層\n",
    "\n",
    "    def forward(self, users, items, adj_list): # ユーザー，アイテム，隣接リスト\n",
    "        user_embeds = self.user_embeddings(users)\n",
    "        item_embeds = self.item_embeddings(items)\n",
    "        \n",
    "        batch_size = len(items)\n",
    "        \n",
    "        aggregated_item_embeds = []\n",
    "        for i in range(batch_size): # 各アイテム\n",
    "            neighbors = adj_list[items[i].item()] # アイテムの隣接ノード（ジャンル）を取得\n",
    "            item_neighbors = torch.tensor(list(neighbors), dtype=torch.long).to(user_embeds.device) # テンソル変換\n",
    "            item_neighbor_embeds = self.item_embeddings(item_neighbors) # アイテムの隣接ノードの埋め込み\n",
    "            # ユーザーの埋め込みとの間でAttention計算\n",
    "            attention = torch.softmax(torch.matmul(user_embeds[i].unsqueeze(0), item_neighbor_embeds.t()), dim=-1)\n",
    "            # Attentionと隣接ノード（ジャンル）の埋め込みベクトルの内積を計算（各隣接ノード（ジャンル）が出力埋め込みにどの程度寄与するか決定）\n",
    "            aggregated_item_embed = torch.matmul(attention, item_neighbor_embeds)\n",
    "            aggregated_item_embeds.append(aggregated_item_embed)\n",
    "        \n",
    "        aggregated_item_embeds = torch.cat(aggregated_item_embeds) # バッチ内のすべてのアイテムの集約された埋め込みを連結\n",
    "        # ユーザーの埋め込みと集約されたアイテム埋め込みの要素ごとの積を計算し，それを合計してスコアを出す．スコアはシグモイド関数で正規化\n",
    "        preds = torch.sigmoid(torch.sum(user_embeds * aggregated_item_embeds, dim=-1))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25602070-de09-4cc9-943b-405c3bfd1252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64 # 埋め込みの次元数\n",
    "num_users = ratings_df['user_id'].max() # ユーザー数\n",
    "num_items = len(movies_df) + len(adj_list) # アイテム（映画+ジャンル数）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d1510-6713-4bcd-8047-b0df11ef2cf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "576e96e6-4e4e-4279-8785-6ca20a5f1950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m ratings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m KGAT(num_users, num_items, \u001b[38;5;28mlen\u001b[39m(genre2id), embedding_dim)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     23\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# K分割交差検証\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "embedding_dim = 64\n",
    "num_users = ratings_df['user_id'].max()\n",
    "num_items = len(movies_df) + len(adj_list)\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "lr = 0.01\n",
    "\n",
    "models = []\n",
    "\n",
    "for train_index, _ in kf.split(ratings_df):\n",
    "    train_df = ratings_df.iloc[train_index]\n",
    "\n",
    "    user_ids = torch.tensor(train_df['user_id'].values, dtype=torch.long)\n",
    "    item_ids = torch.tensor(train_df['movie_id'].values, dtype=torch.long)\n",
    "    ratings = torch.tensor(train_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "    model = KGAT(num_users, num_items, len(genre2id), embedding_dim)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for i in range(0, len(user_ids), batch_size): # ミニバッチごとに\n",
    "            batch_user_ids = user_ids[i:i+batch_size].to(device)\n",
    "            batch_item_ids = item_ids[i:i+batch_size].to(device)\n",
    "            batch_ratings = ratings[i:i+batch_size].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_user_ids, batch_item_ids, adj_list) * 5\n",
    "            loss = criterion(preds, batch_ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(user_ids)}\") # 各エポックでの平均損失\n",
    "\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1749f5-6c54-4a37-8f29-12ae627eeab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769aaa7-eaf6-4420-9f6e-368355ab7eaf",
   "metadata": {},
   "source": [
    "## 推論\n",
    "5つのモデルの平均スコアで性能評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ccacbb-d207-4424-9b7d-5ab7961af9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores = []\n",
    "\n",
    "for _, test_index in kf.split(ratings_df):\n",
    "    test_df = ratings_df.iloc[test_index]\n",
    "    test_user_ids = torch.tensor(test_df['user_id'].values, dtype=torch.long)\n",
    "    test_item_ids = torch.tensor(test_df['movie_id'].values, dtype=torch.long)\n",
    "    test_ratings = torch.tensor(test_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "    mse_per_model = []\n",
    "    for model in models: # モデルごとに\n",
    "        model.eval() # 評価モード\n",
    "        with torch.no_grad(): # 評価では勾配情報無効に\n",
    "            test_preds = model(test_user_ids.to(device), test_item_ids.to(device), adj_list) * 5\n",
    "            mse = mean_squared_error(test_preds.cpu().numpy(), test_ratings.cpu().numpy())\n",
    "            mse_per_model.append(mse)\n",
    "\n",
    "    mse_scores.append(np.mean(mse_per_model)) # 各モデルの平均MSE\n",
    "\n",
    "print(f'Average MSE for {kf.get_n_splits()} folds: {np.mean(mse_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe599097-171c-4676-b7ab-77a9dc3e187c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
